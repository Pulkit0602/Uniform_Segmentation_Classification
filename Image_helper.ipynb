{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nPe__yIOHoF"
      },
      "outputs": [],
      "source": [
        "import pixellib\n",
        "from pixellib.torchbackend.instance import instanceSegmentation\n",
        "import pickle\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVRz1dfzNdP3"
      },
      "source": [
        "To Download the Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVcvEPH7Nbv7"
      },
      "outputs": [],
      "source": [
        "from simple_image_download import simple_image_download as simp\n",
        "from typing import List\n",
        "def download_image(query: List[str]) -> List[str]:\n",
        "  \"\"\"\n",
        "  This function is used to download the 100 images provided a list\n",
        "  \"\"\"\n",
        "  response = simp.simple_image_download\n",
        "  for rep in query:\n",
        "    response().download(rep, 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsA28fH8OIv9"
      },
      "source": [
        "To load the Segmentation Model and its results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NA3p6uluOGOZ"
      },
      "outputs": [],
      "source": [
        "ins = instanceSegmentation()\n",
        "ins.load_model(\"/content/drive/MyDrive/UniformClassification/pointrend_resnet50.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J38yFyyZN85O"
      },
      "source": [
        "To check the crop bounding Box output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8xrkUpdN6zH"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from IPython.display import Image, display\n",
        "\n",
        "def crop_image(image, box):\n",
        "    x_min, y_min, x_max, y_max = box\n",
        "    cropped_image = image[y_min:y_max, x_min:x_max]\n",
        "    return cropped_image\n",
        "\n",
        "\n",
        "\n",
        "# Assuming you uploaded an image named 'uploaded_image.jpg'\n",
        "image_path = '/content/simple_images/CRPF/CRPF_46.jpg\n",
        "# Read the image\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# Example bounding box values (x_min, y_min, x_max, y_max)\n",
        "bounding_box = (6,    2,  199,  526)\n",
        "\n",
        "# Crop the image\n",
        "cropped_image = crop_image(image, bounding_box)\n",
        "\n",
        "# Display the original and cropped images for comparison\n",
        "display(Image(filename=image_path, width=300))\n",
        "display(Image(data=cv2.imencode('.png', cropped_image)[1].tobytes(), width=300))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bp2gk17bNykA"
      },
      "source": [
        "To check the Output after removing Background\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yw8ARy6YNuYH"
      },
      "outputs": [],
      "source": [
        "# Assuming you have your image and mask\n",
        "image = cv2.imread('/content/simple_images/CRPF/CRPF_46.jpg')  # Replace with the actual image file path\n",
        "\n",
        "binary_mask = get_person_reduced_mask(results)\n",
        "\n",
        "# Ensure the mask is binary\n",
        "binary_mask = np.uint8(binary_mask)\n",
        "\n",
        "# Expand the selected channel to cover all channels in the image\n",
        "expanded_mask = np.expand_dims(binary_mask, axis=-1)\n",
        "\n",
        "# Multiply the image with the expanded mask to keep only the foreground\n",
        "result = image * expanded_mask\n",
        "\n",
        "print(result.shape)\n",
        "\n",
        "# Display the original image and the result\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "plt.title('Original Image')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
        "plt.title('Background Removed')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To Hit the API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "# Update with the correct URL of your running Docker container\n",
        "api_url = \"http://localhost:5000/predict\"\n",
        "\n",
        "# Path to the image you want to send for prediction\n",
        "image_path = \"/path/to/your/image.jpg\"\n",
        "\n",
        "# Create a dictionary to include the file in the request\n",
        "files = {'file': open(image_path, 'rb')}\n",
        "\n",
        "# Send a POST request to the API\n",
        "response = requests.post(api_url, files=files)\n",
        "\n",
        "# Check the response\n",
        "if response.status_code == 200:\n",
        "    result = response.json()\n",
        "    predicted_class = result.get('predicted_class')\n",
        "    print(f\"Predicted Class: {predicted_class}\")\n",
        "else:\n",
        "    print(f\"Error: {response.status_code}, {response.text}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
