# -*- coding: utf-8 -*-
"""train_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19TOqx9UpJUtW3h3hW0l8EfvxyY6v6LSz
"""

from google.colab import files
from io import BytesIO
from matplotlib import pyplot as plt

import pixellib
from pixellib.torchbackend.instance import instanceSegmentation
import pickle

import os
import cv2
import numpy as np
from tensorflow.keras import applications
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score
from tqdm.auto import tqdm


import logging
from datetime import datetime
import sys

ins = instanceSegmentation()
ins.load_model("/content/drive/MyDrive/UniformClassification/pointrend_resnet50.pkl")

def get_person_reduced_mask(results, threshold=80):
    """Extract masks for persons with confidence scores above the threshold and combine all the masks"""

    transposed_mask = np.transpose(results["masks"], (2, 0, 1))

    req_transposed_mask = [
        mask for mask, class_id, score in zip(transposed_mask, results["class_ids"], results["scores"])
        if class_id == 0 and score > threshold
    ]

    binary_mask = np.logical_or.reduce(req_transposed_mask, axis=0)

    return binary_mask

def remove_background(image_path, threshold=80):
    """Apply a mask for persons with confidence scores above the threshold to the input image."""

    # path to save images
    processed_image_path = image_path.replace('simple_images', 'processed_image')
    segmented_image_path = image_path.replace('simple_images', 'segmented_image')

    # Read the image
    image = cv2.imread(image_path)

    # Get the binary mask for persons
    results, _ = ins.segmentImage(image_path, show_bboxes=True, output_image_name=segmented_image_path)
    binary_mask = get_person_reduced_mask(results, threshold)

    # Ensure the mask is binary
    binary_mask = np.uint8(binary_mask)

    # Expand the selected channel to cover all channels in the image
    expanded_mask = np.expand_dims(binary_mask, axis=-1)

    # Multiply the image with the expanded mask to keep only the foreground
    result = image * expanded_mask

    cv2.imwrite(processed_image_path, result)

    return result

def preprocess_image(image_path, model_input_size=(224, 224)):
    """Preprocess the image by removing the background, resizing, and applying MobileNetV2 preprocessing."""

    # Remove background
    image_no_bg = remove_background(image_path)

    # Resize and preprocess the image
    image_preprocessed = cv2.resize(image_no_bg, (224, 224))
    image_preprocessed = applications.mobilenet_v2.preprocess_input(image_preprocessed)

    return image_preprocessed

def load_dataset():
    """Load the dataset, preprocess images, and split into training and testing sets."""

    crpf_path = "/content/drive/MyDrive/UniformClassification/simple_images/CRPF"
    fileList = os.listdir(crpf_path)
    image_paths_A = [os.path.join(crpf_path, i) for i in fileList]

    bsf_path = "/content/drive/MyDrive/UniformClassification/simple_images/BSF"
    fileList = os.listdir(bsf_path)
    image_paths_B = [os.path.join(bsf_path, i) for i in fileList]


    J_K_path = "/content/drive/MyDrive/UniformClassification/simple_images/J&K Police"
    fileList = os.listdir(J_K_path)
    image_paths_C = [os.path.join(J_K_path, i) for i in fileList]

    people_path = "/content/drive/MyDrive/UniformClassification/simple_images/People"
    fileList = os.listdir(people_path)
    image_paths_D = [os.path.join(people_path, i) for i in fileList]

    images_A = [preprocess_image(path) for path in tqdm(image_paths_A, desc='Processing CRPF images')]
    images_B = [preprocess_image(path) for path in tqdm(image_paths_B, desc='Processing BSF images')]
    images_C = [preprocess_image(path) for path in tqdm(image_paths_C, desc='Processing J&K C images')]
    images_D = [preprocess_image(path) for path in tqdm(image_paths_D, desc='Processing  images')]

    labels_A = ['CRPF'] * len(images_A)
    labels_B = ['BSF'] * len(images_B)
    labels_C = ['J_K'] * len(images_C)
    labels_D = ['Random'] * len(images_D)

    all_images = np.concatenate([images_A, images_B, images_C, images_D], axis=0)
    all_labels = np.concatenate([labels_A, labels_B, labels_C, labels_D], axis=0)

    # Shuffle and split the dataset into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(
        all_images, all_labels, test_size=0.2, random_state=24, stratify=all_labels, shuffle=True
    )

    return X_train, X_test, y_train, y_test

def build_model(input_shape=(224, 224, 3), num_classes=3):
    """Build a MobileNetV2-based model for uniform classification."""

    base_model = applications.MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)

    model = Sequential()
    model.add(base_model)
    model.add(GlobalAveragePooling2D())
    model.add(Dense(128, activation='relu'))
    model.add(Dropout(0.8))  # Add dropout for regularization
    model.add(Dense(num_classes, activation='softmax'))

    return model

def train_model(X_train, y_train, X_test, y_test):
    """Train a uniform classification model, save the best model, and evaluate its performance."""

    le = LabelEncoder()
    y_train_encoded = le.fit_transform(y_train)
    y_test_encoded = le.transform(y_test)

    model = build_model(num_classes=4)  # Update the number of classes

    # Compile the model
    model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])

    # Define callbacks
    checkpoint_filepath = '/content/drive/MyDrive/UniformClassification/best_model.h5'
    log_file_path = '/content/drive/MyDrive/UniformClassification/training_logs.txt'

    model_checkpoint = ModelCheckpoint(checkpoint_filepath, save_best_only=True, monitor='val_accuracy', mode='max', verbose=1)
    early_stopping = EarlyStopping(monitor='val_accuracy', patience=20, mode='max', verbose=1)

    # Log file setup
    with open(log_file_path, 'a') as log_file:
        log_file.write(f'Training started at {datetime.now()}\n')

    # Train the model with data augmentation including brightness adjustments
    datagen = ImageDataGenerator(
        rotation_range=20,
        width_shift_range=0.2,
        height_shift_range=0.2,
        horizontal_flip=True,
        brightness_range=[0.8, 1.2]  # Adjust the brightness randomly between 0.8 and 1.2
    )
    datagen.fit(X_train)

    model.fit(datagen.flow(X_train, y_train_encoded, batch_size=16),
              steps_per_epoch=len(X_train) / 16,
              validation_data=(X_test, y_test_encoded),
              epochs=100, callbacks=[model_checkpoint, early_stopping])

    # Load the best model
    model.load_weights(checkpoint_filepath)

    # Evaluate the model
    y_pred = np.argmax(model.predict(X_test), axis=1)
    accuracy = accuracy_score(y_test_encoded, y_pred)

    # Save additional training information to log file
    with open(log_file_path, 'a') as log_file:
        log_file.write(f'Test accuracy: {accuracy}\n')
        log_file.write('Training completed at {}\n'.format(datetime.now()))

    return model

if __name__ == "__main__":
    # Load the dataset
    X_train, X_test, y_train, y_test = load_dataset()

    # Train the model
    trained_model = train_model(X_train, y_train, X_test, y_test)